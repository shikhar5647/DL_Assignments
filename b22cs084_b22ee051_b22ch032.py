# -*- coding: utf-8 -*-
"""B22CS084_B22EE051_B22CH032.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdDexQimdtvlNvYccNPKrX4UmxRLD406
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, random_split, Dataset
from torchvision import transforms
from torchvision.datasets import CIFAR100
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score
from torchvision.transforms.functional import to_pil_image

#############################################
# 1. LABEL MAPPINGS
#############################################

# Fine Labels Mapping (0 to 99)
fine_labels = [
    "apple", "aquarium_fish", "baby", "bear", "beaver", "bed", "bee", "beetle",
    "bicycle", "bottle", "bowl", "boy", "bridge", "bus", "butterfly", "camel",
    "can", "castle", "caterpillar", "cattle", "chair", "chimpanzee", "clock",
    "cloud", "cockroach", "couch", "crab", "crocodile", "cup", "dinosaur",
    "dolphin", "elephant", "flatfish", "forest", "fox", "girl", "hamster",
    "house", "kangaroo", "keyboard", "lamp", "lawn_mower", "leopard", "lion",
    "lizard", "lobster", "man", "maple_tree", "motorcycle", "mountain", "mouse",
    "mushroom", "oak_tree", "orange", "orchid", "otter", "palm_tree", "pear",
    "pickup_truck", "pine_tree", "plain", "plate", "poppy", "porcupine",
    "possum", "rabbit", "raccoon", "ray", "road", "rocket", "rose", "sea",
    "seal", "shark", "shrew", "skunk", "skyscraper", "snail", "snake", "spider",
    "squirrel", "streetcar", "sunflower", "sweet_pepper", "table", "tank",
    "telephone", "television", "tiger", "tractor", "train", "trout", "tulip",
    "turtle", "wardrobe", "whale", "willow_tree", "wolf", "woman", "worm"
]

# Coarse Labels Mapping (0 to 19)
coarse_labels = [
    "aquatic_mammals", "fish", "flowers", "food_containers", "fruit_and_vegetables",
    "household_electrical_devices", "household_furniture", "insects",
    "large_carnivores", "large_man-made_outdoor_things", "large_natural_outdoor_scenes",
    "large_omnivores_and_herbivores", "medium_mammals", "non-insect_invertebrates",
    "people", "reptiles", "small_mammals", "trees", "vehicles_1", "vehicles_2"
]

# Synthesized Groups Mapping (0 to 8)
group_names = [
    "Plants/Parts of plants",    # Group 0: if coarse in {flowers (2), fruit_and_vegetables (4), trees (17)}
    "Vehicles",                  # Group 1: if coarse in {vehicles_1 (18), vehicles_2 (19)}
    "Invertebrates",             # Group 2: if coarse in {insects (7), non-insect_invertebrates (13)}
    "Aquatic animals",           # Group 3: if coarse in {aquatic_mammals (0), fish (1)}
    "Large animals",             # Group 4: if coarse in {large_carnivores (8), large_omnivores_and_herbivores (11)}
    "Man-made articles",         # Group 5: if coarse in {food_containers (3), household_electrical_devices (5), household_furniture (6), large_man-made_outdoor_things (9)}
    "People",                    # Group 6: if coarse is people (14)
    "Normal Terrestrial Animals",# Group 7: if coarse in {reptiles (15), medium_mammals (12), small_mammals (16)}
    "Outdoor scenes"             # Group 8: if coarse is large_natural_outdoor_scenes (10)
]

# Standard fine-to-coarse mapping (CIFAR-100 by name)
fine_to_coarse = {
    "apple": 4,
    "aquarium_fish": 1,
    "baby": 14,
    "bear": 8,
    "beaver": 0,
    "bed": 6,
    "bee": 7,
    "beetle": 7,
    "bicycle": 18,
    "bottle": 3,
    "bowl": 3,
    "boy": 14,
    "bridge": 9,
    "bus": 18,
    "butterfly": 7,
    "camel": 11,
    "can": 3,
    "castle": 9,
    "caterpillar": 7,
    "cattle": 11,
    "chair": 6,
    "chimpanzee": 11,
    "clock": 5,
    "cloud": 10,
    "cockroach": 7,
    "couch": 6,
    "crab": 13,
    "crocodile": 15,
    "cup": 3,
    "dinosaur": 15,
    "dolphin": 0,
    "elephant": 11,
    "flatfish": 1,
    "forest": 10,
    "fox": 12,
    "girl": 14,
    "hamster": 16,
    "house": 9,
    "kangaroo": 11,
    "keyboard": 5,
    "lamp": 5,
    "lawn_mower": 19,
    "leopard": 8,
    "lion": 8,
    "lizard": 15,
    "lobster": 13,
    "man": 14,
    "maple_tree": 17,
    "motorcycle": 18,
    "mountain": 10,
    "mouse": 16,
    "mushroom": 4,
    "oak_tree": 17,
    "orange": 4,
    "orchid": 2,
    "otter": 0,
    "palm_tree": 17,
    "pear": 4,
    "pickup_truck": 18,
    "pine_tree": 17,
    "plain": 10,
    "plate": 3,
    "poppy": 2,
    "porcupine": 12,
    "possum": 12,
    "rabbit": 16,
    "raccoon": 12,
    "ray": 1,
    "road": 9,
    "rocket": 19,
    "rose": 2,
    "sea": 10,
    "seal": 0,
    "shark": 1,
    "shrew": 16,
    "skunk": 12,
    "skyscraper": 9,
    "snail": 13,
    "snake": 15,
    "spider": 13,
    "squirrel": 16,
    "streetcar": 19,
    "sunflower": 2,
    "sweet_pepper": 4,
    "table": 6,
    "tank": 19,
    "telephone": 5,
    "television": 5,
    "tiger": 8,
    "tractor": 19,
    "train": 18,
    "trout": 1,
    "tulip": 2,
    "turtle": 15,
    "wardrobe": 6,
    "whale": 0,
    "willow_tree": 17,
    "wolf": 8,
    "woman": 14,
    "worm": 13
}

# Helper: Map coarse index to synthesized group index.
def coarse_to_group(coarse_index):
    if coarse_index in {2, 4, 17}:  # flowers, fruit_and_vegetables, trees
        return 0  # Plants/Parts of plants
    elif coarse_index in {18, 19}:   # vehicles_1, vehicles_2
        return 1  # Vehicles
    elif coarse_index in {7, 13}:    # insects, non-insect_invertebrates
        return 2  # Invertebrates
    elif coarse_index in {0, 1}:     # aquatic_mammals, fish
        return 3  # Aquatic animals
    elif coarse_index in {8, 11}:    # large_carnivores, large_omnivores_and_herbivores
        return 4  # Large animals
    elif coarse_index in {3, 5, 6, 9}:  # food_containers, household_electrical_devices, household_furniture, large_man-made_outdoor_things
        return 5  # Man-made articles
    elif coarse_index == 14:         # people
        return 6  # People
    elif coarse_index in {15, 12, 16}:  # reptiles, medium_mammals, small_mammals
        return 7  # Normal Terrestrial Animals
    elif coarse_index == 10:         # large_natural_outdoor_scenes
        return 8  # Outdoor scenes
    else:
        return -1

# Build mapping: fine label name -> (coarse index, group index)
fine_to_coarse_group = {}
for fname, cidx in fine_to_coarse.items():
    gidx = coarse_to_group(cidx)
    fine_to_coarse_group[fname] = (cidx, gidx)

#############################################
# 2. CUSTOM DATASET DEFINITION
#############################################

class CIFAR100MultiLabel(Dataset):
    """
    Wraps torchvision's CIFAR-100 to return:
       (image, fine_label, coarse_label, group_label)
    where coarse and group labels are derived from our mapping.
    """
    def __init__(self, root, train=True, transform=None, download=False):
        self.dataset = CIFAR100(root=root, train=train, transform=transform, download=download)
        self.fine_labels_list = fine_labels  # ordering for fine labels
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, index):
        image, fine_label = self.dataset[index]
        fine_name = self.fine_labels_list[fine_label]
        # Retrieve coarse and group indices from mapping
        coarse_label, group_label = fine_to_coarse_group[fine_name]
        return image, fine_label, coarse_label, group_label

#############################################
# 3. MODEL DEFINITION: MULTI-HEAD CNN
#############################################

class MultiHeadCNN(nn.Module):
    def __init__(self, num_fine=100, num_coarse=20, num_groups=9):
        super(MultiHeadCNN, self).__init__()
        # Shared CNN backbone (VGG-inspired)
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 32 -> 16

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 16 -> 8

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)   # 8 -> 4
        )
        self.avgpool = nn.AdaptiveAvgPool2d((1,1))
        self.flatten = nn.Flatten()
        self.fc_shared = nn.Linear(256, 512)
        self.dropout = nn.Dropout(0.5)

        # Three separate heads:
        self.fc_fine = nn.Linear(512, num_fine)
        self.fc_coarse = nn.Linear(512, num_coarse)
        self.fc_group = nn.Linear(512, num_groups)

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = self.flatten(x)
        x = self.fc_shared(x)
        x = self.dropout(x)
        out_fine = self.fc_fine(x)
        out_coarse = self.fc_coarse(x)
        out_group = self.fc_group(x)
        return out_fine, out_coarse, out_group

#############################################
# 4. TRAINING, EVALUATION, AND UTILITY FUNCTIONS
#############################################

def train_one_epoch(model, loader, optimizer, criterion_fine, criterion_coarse, criterion_group, device):
    model.train()
    running_loss = 0.0
    for images, fine_labels, coarse_labels, group_labels in loader:
        images = images.to(device)
        fine_labels = fine_labels.to(device)
        coarse_labels = coarse_labels.to(device)
        group_labels = group_labels.to(device)

        optimizer.zero_grad()
        out_fine, out_coarse, out_group = model(images)
        loss_fine = criterion_fine(out_fine, fine_labels)
        loss_coarse = criterion_coarse(out_coarse, coarse_labels)
        loss_group = criterion_group(out_group, group_labels)
        total_loss = loss_fine + loss_coarse + loss_group
        total_loss.backward()
        optimizer.step()
        running_loss += total_loss.item() * images.size(0)
    return running_loss / len(loader.dataset)

def evaluate(model, loader, criterion_fine, criterion_coarse, criterion_group, device):
    model.eval()
    total_loss = 0.0
    all_fine_preds, all_fine_labels = [], []
    all_coarse_preds, all_coarse_labels = [], []
    all_group_preds, all_group_labels = [], []
    with torch.no_grad():
        for images, fine_labels, coarse_labels, group_labels in loader:
            images = images.to(device)
            fine_labels = fine_labels.to(device)
            coarse_labels = coarse_labels.to(device)
            group_labels = group_labels.to(device)
            out_fine, out_coarse, out_group = model(images)
            loss = criterion_fine(out_fine, fine_labels) + \
                   criterion_coarse(out_coarse, coarse_labels) + \
                   criterion_group(out_group, group_labels)
            total_loss += loss.item() * images.size(0)
            fine_preds = out_fine.argmax(dim=1).cpu().numpy()
            coarse_preds = out_coarse.argmax(dim=1).cpu().numpy()
            group_preds = out_group.argmax(dim=1).cpu().numpy()
            all_fine_preds.extend(fine_preds)
            all_fine_labels.extend(fine_labels.cpu().numpy())
            all_coarse_preds.extend(coarse_preds)
            all_coarse_labels.extend(coarse_labels.cpu().numpy())
            all_group_preds.extend(group_preds)
            all_group_labels.extend(group_labels.cpu().numpy())
    avg_loss = total_loss / len(loader.dataset)
    fine_acc = accuracy_score(all_fine_labels, all_fine_preds)
    coarse_acc = accuracy_score(all_coarse_labels, all_coarse_preds)
    group_acc = accuracy_score(all_group_labels, all_group_preds)
    return avg_loss, fine_acc, coarse_acc, group_acc, all_fine_labels, all_fine_preds, all_coarse_labels, all_coarse_preds, all_group_labels, all_group_preds

def plot_confusion_matrix(y_true, y_pred, classes, title, figsize=(20,20), fontsize=8):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=figsize)
    ax = sns.heatmap(cm, annot=True, fmt="d", xticklabels=classes, yticklabels=classes, cmap='Blues', annot_kws={"size": fontsize})
    plt.title(title, fontsize=fontsize+4)
    plt.ylabel('True label', fontsize=fontsize+2)
    plt.xlabel('Predicted label', fontsize=fontsize+2)
    plt.xticks(fontsize=fontsize, rotation=90)
    plt.yticks(fontsize=fontsize, rotation=0)
    plt.show()

def count_parameters(model):
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable = sum(p.numel() for p in model.parameters() if not p.requires_grad)
    return trainable, non_trainable

#############################################
# 5. DATA PREPARATION & EXPERIMENTS WITH DIFFERENT SPLITS
#############################################

# Data transforms
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))
])

# Create our custom dataset (download CIFAR-100 if needed)
dataset = CIFAR100MultiLabel(root='./data', train=True, transform=transform_train, download=True)

# Use an 80:20 train:test split (can be modified to try other splits)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)

# Loss functions for fine and coarse heads (standard CrossEntropy)
criterion_fine = nn.CrossEntropyLoss()
criterion_coarse = nn.CrossEntropyLoss()

# For the synthesized group head, compute class weights to handle imbalance
group_labels_train = [dataset[i][3] for i in train_dataset.indices]
counts = np.bincount(group_labels_train, minlength=9)
group_weights = 1.0 / (counts + 1e-6)
group_weights = group_weights / np.sum(group_weights) * 9  # Scale to number of groups
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
group_weights = torch.tensor(group_weights, dtype=torch.float).to(device)
criterion_group = nn.CrossEntropyLoss(weight=group_weights)

# Instantiate model and optimizer (using weight decay to reduce overfitting)
model = MultiHeadCNN(num_fine=100, num_coarse=20, num_groups=9).to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)

# Set up a learning rate scheduler based on validation loss
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)

num_epochs = 50

for epoch in range(num_epochs):
    train_loss = train_one_epoch(model, train_loader, optimizer, criterion_fine, criterion_coarse, criterion_group, device)
    train_loss_eval, fine_train_acc, coarse_train_acc, group_train_acc, *_ = evaluate(model, train_loader, criterion_fine, criterion_coarse, criterion_group, device)
    total_train_acc = (fine_train_acc + coarse_train_acc + group_train_acc) / 3.0

    val_loss, fine_val_acc, coarse_val_acc, group_val_acc, *_ = evaluate(model, val_loader, criterion_fine, criterion_coarse, criterion_group, device)
    total_val_acc = (fine_val_acc + coarse_val_acc + group_val_acc) / 3.0

    # Step the scheduler with the validation loss
    scheduler.step(val_loss)

    print(f"Epoch {epoch+1:02d}/{num_epochs:02d}")
    print(f"   Train Loss: {train_loss:.4f}, Train Acc: Fine: {fine_train_acc*100:.2f}%, "
          f"Coarse: {coarse_train_acc*100:.2f}%, Group: {group_train_acc*100:.2f}%, "
          f"Total: {total_train_acc*100:.2f}%")
    print(f"   Val   Loss: {val_loss:.4f}, Val   Acc: Fine: {fine_val_acc*100:.2f}%, "
          f"Coarse: {coarse_val_acc*100:.2f}%, Group: {group_val_acc*100:.2f}%, "
          f"Total: {total_val_acc*100:.2f}%")

# Final evaluation on validation set
val_loss, fine_val_acc, coarse_val_acc, group_val_acc, fine_labels_eval, fine_preds, coarse_labels_eval, coarse_preds, group_labels_eval, group_preds = evaluate(model, val_loader, criterion_fine, criterion_coarse, criterion_group, device)
print(f"\nFinal Validation Loss: {val_loss:.4f}")
print(f"Final Fine Accuracy: {fine_val_acc*100:.2f}%")
print(f"Final Coarse Accuracy: {coarse_val_acc*100:.2f}%")
print(f"Final Group Accuracy: {group_val_acc*100:.2f}%")
total_acc_val = (fine_val_acc + coarse_val_acc + group_val_acc ) / 3.0
print(f"Final Total Accuracy: {total_acc_val*100:.2f}%")
# Plot confusion matrices for all three heads.
# For the 100-class fine head, we use a larger figure to avoid clutter.
plot_confusion_matrix(fine_labels_eval, fine_preds, classes=fine_labels, title="Fine Head Confusion Matrix", figsize=(20,20), fontsize=6)
plot_confusion_matrix(coarse_labels_eval, coarse_preds, classes=coarse_labels, title="Coarse Head Confusion Matrix", figsize=(10,8), fontsize=10)
plot_confusion_matrix(group_labels_eval, group_preds, classes=group_names, title="Group Head Confusion Matrix", figsize=(8,6), fontsize=12)

#############################################
# 6. BONUS: SEVERITY LOSS FOR FINE CLASSIFICATION (Single Head)
#############################################

class SeverityLoss(nn.Module):
    """
    Custom loss: multiplies standard cross-entropy loss by a severity factor.
    Severity factor:
      - 1 if predicted and true fine labels share the same coarse category,
      - 2 if they share the same synthesized group (but not same coarse),
      - 3 otherwise.
    """
    def __init__(self, fine_to_coarse_group):
        super(SeverityLoss, self).__init__()
        self.fine_to_coarse_group = fine_to_coarse_group
        self.ce = nn.CrossEntropyLoss(reduction='none')

    def forward(self, logits, targets):
        loss = self.ce(logits, targets)  # (batch,)
        preds = logits.argmax(dim=1)
        severity = torch.zeros_like(loss)
        for i in range(len(targets)):
            true_name = fine_labels[targets[i].item()]
            pred_name = fine_labels[preds[i].item()]
            true_coarse, true_group = self.fine_to_coarse_group[true_name]
            pred_coarse, pred_group = self.fine_to_coarse_group[pred_name]
            if true_coarse == pred_coarse:
                sev = 1
            elif true_group == pred_group:
                sev = 2
            else:
                sev = 3
            severity[i] = sev
        return (loss * severity).mean()

print("\n==== BONUS: Training with Severity Loss (Fine Head Only) ====")
# For bonus, use an 80:20 train/test split.
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset_bonus, val_dataset_bonus = random_split(dataset, [train_size, val_size])
train_loader_bonus = DataLoader(train_dataset_bonus, batch_size=128, shuffle=True, num_workers=2)
val_loader_bonus = DataLoader(val_dataset_bonus, batch_size=128, shuffle=False, num_workers=2)

model_bonus = MultiHeadCNN(num_fine=100, num_coarse=20, num_groups=9).to(device)
optimizer_bonus = optim.Adam(model_bonus.parameters(), lr=1e-3, weight_decay=1e-4)
severity_loss_fn = SeverityLoss(fine_to_coarse_group)
num_epochs_bonus = 50

for epoch in range(num_epochs_bonus):
    model_bonus.train()
    running_loss = 0.0
    for images, fine_labels_batch, _, _ in train_loader_bonus:
        images = images.to(device)
        fine_labels_batch = fine_labels_batch.to(device)
        optimizer_bonus.zero_grad()
        out_fine, _, _ = model_bonus(images)
        loss = severity_loss_fn(out_fine, fine_labels_batch)
        loss.backward()
        optimizer_bonus.step()
        running_loss += loss.item() * images.size(0)
    avg_loss = running_loss / len(train_loader_bonus.dataset)
    print(f"Epoch {epoch+1:02d}/{num_epochs_bonus:02d} | Loss: {avg_loss:.4f}")

model_bonus.eval()
all_preds_bonus, all_labels_bonus = [], []
with torch.no_grad():
    for images, fine_labels_batch, _, _ in val_loader_bonus:
        images = images.to(device)
        fine_labels_batch = fine_labels_batch.to(device)
        out_fine, _, _ = model_bonus(images)
        preds = out_fine.argmax(dim=1)
        all_preds_bonus.extend(preds.cpu().numpy())
        all_labels_bonus.extend(fine_labels_batch.cpu().numpy())
bonus_acc = accuracy_score(all_labels_bonus, all_preds_bonus)
print(f"\nBonus Model Fine Classification Accuracy: {bonus_acc*100:.2f}%")

# Plot confusion matrix for bonus model fine head
plot_confusion_matrix(all_labels_bonus, all_preds_bonus, classes=fine_labels, title="Bonus Model Fine Head Confusion Matrix", figsize=(20,20), fontsize=6)

# --- Compute Severity Distribution ---
def compute_severity_distribution(model, loader, device, fine_to_coarse_group, fine_labels_list):
    model.eval()
    severity_counts = {1: 0, 2: 0, 3: 0}
    total_misclassified = 0
    with torch.no_grad():
        for images, fine_labels_batch, _, _ in loader:
            images = images.to(device)
            fine_labels_batch = fine_labels_batch.to(device)
            out_fine, _, _ = model(images)
            preds = out_fine.argmax(dim=1)
            for i in range(len(fine_labels_batch)):
                if preds[i] != fine_labels_batch[i]:
                    true_name = fine_labels_list[fine_labels_batch[i].item()]
                    pred_name = fine_labels_list[preds[i].item()]
                    true_coarse, true_group = fine_to_coarse_group[true_name]
                    pred_coarse, pred_group = fine_to_coarse_group[pred_name]
                    if true_coarse == pred_coarse:
                        severity_counts[1] += 1
                    elif true_group == pred_group:
                        severity_counts[2] += 1
                    else:
                        severity_counts[3] += 1
                    total_misclassified += 1
    return severity_counts, total_misclassified

severity_counts, total_misclassified = compute_severity_distribution(model_bonus, val_loader_bonus, device, fine_to_coarse_group, fine_labels)
if total_misclassified > 0:
    avg_severity = (1*severity_counts[1] + 2*severity_counts[2] + 3*severity_counts[3]) / total_misclassified
else:
    avg_severity = 0.0
print("\n--- Severity Loss Model Analysis ---")
print(f"Total misclassified samples: {total_misclassified}")
print(f"Severity distribution: {severity_counts}")
print(f"Average severity of misclassifications: {avg_severity:.2f}")

# Plot severity distribution as a bar chart.
plt.figure(figsize=(6,4))
plt.bar(list(severity_counts.keys()), list(severity_counts.values()), color=['green','orange','red'])
plt.xlabel("Severity Level")
plt.ylabel("Number of Misclassifications")
plt.title("Severity Distribution (Bonus Model)")
plt.xticks([1,2,3])
plt.show()

#############################################
# 7. SHOWCASE SECTION: DISPLAY EXAMPLES FROM THE DATASET
#############################################

def showcase_dataset(dataset, num_examples=5):
    """
    Display a few examples from the dataset with their fine, coarse, and group labels.
    """
    plt.figure(figsize=(15,3))
    for i in range(num_examples):
        img, fine_label, coarse_label, group_label = dataset[i]
        fine_name = fine_labels[fine_label]
        coarse_name = coarse_labels[coarse_label]
        group_name = group_names[group_label]
        plt.subplot(1, num_examples, i+1)
        if isinstance(img, torch.Tensor):
            img = to_pil_image(img)
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"Fine: {fine_name}\nCoarse: {coarse_name}\nGroup: {group_name}")
    plt.show()

# Create a dataset instance (using test transforms) and showcase examples.
transform_show = transforms.Compose([transforms.ToTensor()])
showcase_ds = CIFAR100MultiLabel(root='./data', train=True, transform=transform_show, download=True)
showcase_dataset(showcase_ds, num_examples=5)


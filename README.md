## DL_Assignments
# Assignment 1 : 
This project implements a neural network from scratch in Python to classify handwritten digits from the MNIST dataset. The images, sized 28x28, are flattened into 784-dimensional normalized vectors. The dataset is imported using TensorFlow, and one-hot encoding is applied to the labels to align with the categorical cross-entropy loss function. The network architecture includes an input layer, a hidden layer with configurable activation functions (ReLU, sigmoid, tanh), and an output layer with softmax for multiclass classification. Various weight initialization techniques such as Xavier, He, and random initialization were experimented with, alongside L2 regularization to prevent overfitting. The forward and backward pass functions are implemented from scratch, with gradients computed manually for efficient learning.

Thee model supports stochastic, batch, and mini-batch gradient descent optimization modes, with mini-batch gradient descent yielding the best results when combined with ReLU activation and He initialization. A custom learning rate scheduler adjusts the learning rate dynamically based on validation loss trends to optimize convergence. Early stopping is incorporated to halt training when no improvement is observed, enhancing model generalization. Extensive experimentation with different configurations resulted in 27 performance plots, showcasing validation loss and accuracy across epochs. This rigorous approach highlighted the superior performance of the ReLU-He-Mini-batch combination, achieving faster convergence, robust gradient flow, and improved accuracy.


